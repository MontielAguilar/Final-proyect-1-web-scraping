<p align="center">
  <img src="https://png.pngtree.com/png-vector/20210908/ourmid/pngtree-united-kingdom-flag-png-with-transparent-background-png-image_3917557.jpg" alt="Banner" style="border-radius: 90%;">
</p>

Web Scraping: Idealista Scraper
Description
The data extraction from Idealista's website has been a significant challenge due to the complexity of obstruction methods implemented by the site. This process was tackled to leverage the richness and reliability of data available on Idealista, despite the inherent complications in web scraping.

Reasons for Choosing Idealista
The selection of Idealista as a data source was based on its relevance to the project and the opportunity to face and overcome complex technical challenges. Extracting data from a platform with advanced security measures required not only web scraping knowledge but also the ability to adapt to changes in obstruction tactics over time.

Extraction Method: Python and Web Scraping
Python was chosen as the foundation for data extraction due to the lack of an API that met all requirements (reliability, accuracy, and free availability). Although APIs could have been a simpler option, the complexity of specific needs led to the development of custom scraping code using Python.

Use of HideMyAss (HMA)
To overcome Idealista's anti-scraping measures, VPN/IP rotation was implemented using the HMA API. This tool allows automatic IP address changes every 1-5 minutes, proving useful to avoid detection and blocking by Idealista.
HMA was employed to dynamically change IP addresses, providing anonymity and avoiding detection by Idealista. IP rotation was essential for the success of large-scale scraping.
HMA ensures online privacy and security by hiding the real IP address, encrypting internet traffic, and offering virtual locations worldwide. Additionally, it provides IP rotation, being crucial for scraping on Idealista.

Main Obstacles and Solutions
Idealista implements various measures to prevent automated extraction, such as speed limits, captchas, user sessions, page structure limitations, behavior analysis, and IP address blocking. These obstacles were overcome through various strategies, including scraping flow division, the use of rotating VPN/IP, and IP rotation to avoid temporary blocks.

Scraping Code
The Python language was used along with the libraries requests, BeautifulSoup, and undetected_chromedriver. The code addresses the automatic opening of the browser, automatic cookie acceptance, HTML retrieval, specific information extraction, element searching, and IP rotation with HMA.

Considerations
It is essential to consider HMA's log policy and adjust the browser settings to avoid automatic updates that may affect compatibility with the undetected_chromedriver library.

Conclusions
The choice of Idealista as a data source, coupled with the use of Python and HMA, allowed overcoming inherent technical challenges in scraping and obtaining a comprehensive and detailed dataset for the project.



<p align="center">
  <img src="https://c0.klipartz.com/pngpicture/288/791/gratis-png-bandera-de-espana-bandera-de-espana-bandera-de-la-bandera-nacional-de-estados-unidos-icono-de-banderas-de-espana-thumbnail.png" alt="Banner" style="border-radius: 90%;">
</p>

# Web Scraping: Idealista Scraper
Descripción
La obtención de datos de la página web de Idealista ha sido un desafío significativo debido a la complejidad de los métodos de obstrucción implementados por el sitio. Este proceso se abordó para aprovechar la riqueza y confiabilidad de los datos disponibles en Idealista, a pesar de las complicaciones inherentes al scraping.

# Razones para elegir Idealista
La elección de Idealista como fuente de datos se basó en su relevancia para el proyecto y la oportunidad de enfrentar y superar desafíos técnicos complejos. La extracción de datos de una plataforma con medidas de seguridad avanzadas no solo requirió conocimientos de web scraping, sino también la capacidad de adaptarse a cambios en las tácticas de obstrucción a lo largo del tiempo.

# Método de Extracción: Python y Web Scraping
Se optó por utilizar Python como base para la extracción de datos, debido a la falta de una API que satisficiera todos los requisitos (fiabilidad, precisión y disponibilidad gratuita). Aunque las APIs podrían haber sido una opción más sencilla, la complejidad de las necesidades específicas llevó al desarrollo de un código de scraping personalizado utilizando Python.

# Uso de HideMyAss (HMA)
Para superar las medidas anti-scraping de Idealista, se implementó la rotación de VPN/IP utilizando la API HMA. Esta herramienta permite cambiar automáticamente la dirección IP cada 1-5 minutos, lo que resultó útil para evitar la detección y bloqueo por parte de Idealista.
HMA se empleó para cambiar dinámicamente las direcciones IP, proporcionando anonimato y evitando la detección por parte de Idealista. La rotación de IP fue esencial para el éxito del scraping a gran escala.
HMA garantiza la privacidad y seguridad en línea al ocultar la dirección IP real, cifrar el tráfico de internet y ofrecer ubicaciones virtuales en todo el mundo. Además, proporciona rotación de IP, siendo esencial para el scraping en Idealista.

# Principales Obstáculos y Soluciones
Idealista implementa diversas medidas para evitar la extracción automatizada, como límites de velocidad, Captchas, sesiones de usuario, limitación en la estructura de páginas, análisis del comportamiento y bloqueo de direcciones IP. Estos obstáculos se superaron mediante diversas estrategias, como la división del flujo de scraping, el uso de VPN/IP rotativo, y la rotación de IP para evitar bloqueos temporales.

# Código de Scraping
Se utilizó el lenguaje Python junto con las bibliotecas requests, BeautifulSoup, y undetected_chromedriver. El código aborda la apertura automática del navegador, aceptación automática de cookies, obtención del HTML, extracción de información específica, búsqueda de elementos, y la rotación de IP con HMA.

# Consideraciones
Es importante tener en cuenta la política de registros de HMA y ajustar la configuración del navegador para evitar actualizaciones automáticas que puedan afectar la compatibilidad con la librería undetected_chromedriver.

# Conclusiones
La elección de Idealista como fuente de datos, junto con el uso de Python y HMA, permitió superar los desafíos técnicos inherentes al scraping y obtener un conjunto completo y detallado de datos para el proyecto.

